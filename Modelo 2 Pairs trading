!pip install keras-tuner
import numpy as np
import pandas as pd
import yfinance as yf
import statsmodels.api as sm
from statsmodels.tsa.stattools import adfuller, coint
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, TimeSeriesSplit
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from concurrent.futures import ProcessPoolExecutor
import logging
from datetime import datetime

# Configurações iniciais
IBOVESPA_TICKERS = [
    "ABEV3.SA", "ASAI3.SA", "AURE3.SA", "AZUL4.SA", "AZZA3.SA", "B3SA3.SA", "BBSE3.SA", "BBDC3.SA",
    "BBDC4.SA", "BRAP4.SA", "BBAS3.SA", "BRKM5.SA", "BRFS3.SA", "BPAC11.SA", "CXSE3.SA", "CRFB3.SA",
    "CCRO3.SA", "CMIG4.SA", "COGN3.SA", "CPLE6.SA", "CSAN3.SA", "CPFE3.SA", "CMIN3.SA", "CVCB3.SA",
    "CYRE3.SA", "ELET3.SA", "ELET6.SA", "EMBR3.SA", "ENGI11.SA", "ENEV3.SA", "EGIE3.SA", "EQTL3.SA",
    "FLRY3.SA", "GGBR4.SA", "GOAU4.SA", "NTCO3.SA", "HAPV3.SA", "HYPE3.SA", "IGTI11.SA", "IRBR3.SA",
    "ITSA4.SA", "ITUB4.SA", "JBSS3.SA", "KLBN11.SA", "RENT3.SA", "LREN3.SA", "LWSA3.SA", "MGLU3.SA",
    "POMO4.SA", "MRFG3.SA", "BEEF3.SA", "MRVE3.SA", "MULT3.SA", "PCAR3.SA", "PETR3.SA", "PETR4.SA",
    "RECV3.SA", "PRIO3.SA", "PETZ3.SA", "PSSA3.SA", "RADL3.SA", "RAIZ4.SA", "RDOR3.SA", "RAIL3.SA",
    "SBSP3.SA", "SANB11.SA", "STBP3.SA", "SMTO3.SA", "CSNA3.SA", "SLCE3.SA", "SUZB3.SA", "TAEE11.SA",
    "VIVT3.SA", "TIMS3.SA", "TOTS3.SA", "UGPA3.SA", "USIM5.SA", "VALE3.SA", "VAMO3.SA", "VBBR3.SA",
    "VIVA3.SA", "WEGE3.SA", "YDUQ3.SA"
]

START_DATE = '2018-01-01'
END_DATE = datetime.today().strftime('%Y-%m-%d')  # Data final sempre será a data atual
TRAIN_TEST_SPLIT = 0.8  # Proporção de dados para treino
Z_SCORE_THRESHOLD = 2.0  # Limite para divergência no spread
MIN_COINTEGRATION_PVALUE = 0.1  # Limiar relaxado para testes
MIN_DATA_POINTS = 252  # Mínimo de pontos de dados (aprox. 1 ano de negociação)
MAX_PAIRS_TO_EVALUATE = 500  # Limitar o número de pares a serem avaliados

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Função para baixar dados históricos
def download_data(tickers, start_date, end_date):
    try:
        data = yf.download(tickers, start=start_date, end=end_date)['Close']
        if data.isnull().values.any():
            logging.warning("Dados contêm valores nulos. Removendo ativos com dados incompletos...")
            data = data.dropna(axis=1)
        if data.empty or len(data) < MIN_DATA_POINTS:
            raise ValueError("Dados insuficientes para análise.")
        logging.info(f"Dados baixados com sucesso: {data.shape[1]} ativos e {data.shape[0]} dias.")
        return data
    except Exception as e:
        logging.error(f"Erro ao baixar dados: {e}")
        return None

# Função para calcular o spread
def calculate_spread(stock1, stock2):
    model = sm.OLS(stock1, stock2).fit()
    hedge_ratio = model.params[0]
    spread = stock1 - hedge_ratio * stock2
    return spread, hedge_ratio

# Função para verificar cointegração
def check_cointegration(S1, S2):
    try:
        score, pvalue, _ = coint(S1, S2)
        if pvalue < MIN_COINTEGRATION_PVALUE:
            spread, _ = calculate_spread(S1, S2)
            adf_test = adfuller(spread)
            if adf_test[1] < MIN_COINTEGRATION_PVALUE:
                return True, pvalue
        return False, pvalue
    except Exception as e:
        logging.error(f"Erro ao testar cointegração: {e}")
        return False, None

# Função para processar um par (agora global)
def process_pair(pair, data):
    i, j = pair
    keys = data.keys()
    S1 = data[keys[i]]
    S2 = data[keys[j]]
    is_cointegrated, pvalue = check_cointegration(S1, S2)
    if is_cointegrated:
        logging.info(f"Par cointegrado encontrado: {keys[i]} e {keys[j]} (p-value: {pvalue:.4f})")
        return (keys[i], keys[j], pvalue)
    return None

# Função auxiliar para mapear os pares
def map_process_pair(pair, data):
    return process_pair(pair, data)

# Função para encontrar pares cointegrados (paralelizada)
def find_cointegrated_pairs(data):
    n = data.shape[1]
    keys = data.keys()
    pairs = []

    # Pré-filtragem por correlação para reduzir o número de pares
    corr_matrix = data.corr()
    upper_tri = np.triu(corr_matrix, k=1)
    top_pairs = np.dstack(np.unravel_index(np.argsort(-upper_tri.ravel()), upper_tri.shape))[0][:MAX_PAIRS_TO_EVALUATE]
    logging.info(f"Pré-filtragem concluída: {len(top_pairs)} pares selecionados para avaliação.")

    with ProcessPoolExecutor() as executor:
        results = executor.map(map_process_pair, top_pairs, [data] * len(top_pairs))

    for result in results:
        if result:
            pairs.append(result)

    if not pairs:
        logging.warning("Nenhum par cointegrado encontrado após a análise.")
    else:
        logging.info(f"{len(pairs)} pares cointegrados encontrados.")
    return pairs

# Função para normalizar o spread (z-score)
def normalize_spread(spread):
    mean = spread.mean()
    std = spread.std()
    z_scores = (spread - mean) / std
    return z_scores

# Função principal
def main():
    # Baixar dados históricos
    logging.info("Baixando dados históricos...")
    data = download_data(IBOVESPA_TICKERS, START_DATE, END_DATE)
    if data is None:
        logging.error("Não foi possível obter dados históricos válidos.")
        return

    # Encontrar pares cointegrados
    logging.info("Encontrando pares cointegrados...")
    pairs = find_cointegrated_pairs(data)
    if not pairs:
        logging.warning("Nenhum par cointegrado encontrado. Encerrando execução.")
        return

    # Selecionar o primeiro par para análise
    stock1_ticker, stock2_ticker, _ = pairs[0]
    stock1 = data[stock1_ticker]
    stock2 = data[stock2_ticker]

    # Calcular o spread
    logging.info("Calculando spread...")
    spread, hedge_ratio = calculate_spread(stock1, stock2)
    z_scores = normalize_spread(spread)

    # Dividir dados em treino e teste
    X = z_scores.values.reshape(-1, 1)
    y = np.where(z_scores > Z_SCORE_THRESHOLD, -1, np.where(z_scores < -Z_SCORE_THRESHOLD, 1, 0))
    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=TRAIN_TEST_SPLIT, shuffle=False)

    # Treinar a rede neural
    logging.info("Treinando rede neural...")
    model = Sequential([
        Dense(32, activation='relu', input_shape=(X_train.shape[1],)),
        Dense(16, activation='relu'),
        Dense(1, activation='linear')
    ])
    model.compile(optimizer='adam', loss='mse')
    model.fit(X_train, y_train, epochs=20, batch_size=64, verbose=0)

    # Avaliar o modelo
    test_predictions = model.predict(X_test)
    test_predictions = np.where(test_predictions > 0.5, 1, np.where(test_predictions < -0.5, -1, 0))

    # Gerar sinais de trading
    last_z_score = z_scores.iloc[-1]
    signal = None
    if last_z_score > Z_SCORE_THRESHOLD:
        signal = "SELL"
    elif last_z_score < -Z_SCORE_THRESHOLD:
        signal = "BUY"

    # Recomendações de compra e venda
    if signal == "BUY":
        logging.info(f"Recomendação: COMPRAR {stock1_ticker} e VENDER {stock2_ticker}")
        capital = 10000  # Capital disponível para investimento
        price_stock1 = stock1.iloc[-1]
        price_stock2 = stock2.iloc[-1]
        qty_stock1 = int(capital / price_stock1)
        qty_stock2 = int(qty_stock1 * hedge_ratio)
        total_cost_stock1 = qty_stock1 * price_stock1
        total_cost_stock2 = qty_stock2 * price_stock2
        logging.info(f"Comprar {qty_stock1} ações de {stock1_ticker} por R${price_stock1:.2f} cada (Total: R${total_cost_stock1:.2f})")
        logging.info(f"Vender {qty_stock2} ações de {stock2_ticker} por R${price_stock2:.2f} cada (Total: R${total_cost_stock2:.2f})")
    elif signal == "SELL":
        logging.info(f"Recomendação: VENDER {stock1_ticker} e COMPRAR {stock2_ticker}")
        capital = 10000  # Capital disponível para investimento
        price_stock1 = stock1.iloc[-1]
        price_stock2 = stock2.iloc[-1]
        qty_stock1 = int(capital / price_stock1)
        qty_stock2 = int(qty_stock1 * hedge_ratio)
        total_cost_stock1 = qty_stock1 * price_stock1
        total_cost_stock2 = qty_stock2 * price_stock2
        logging.info(f"Vender {qty_stock1} ações de {stock1_ticker} por R${price_stock1:.2f} cada (Total: R${total_cost_stock1:.2f})")
        logging.info(f"Comprar {qty_stock2} ações de {stock2_ticker} por R${price_stock2:.2f} cada (Total: R${total_cost_stock2:.2f})")
    else:
        logging.info("Nenhuma recomendação de trading no momento.")

if __name__ == "__main__":
    main()
